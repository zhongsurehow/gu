#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒå¼•æ“ä¼˜åŒ–æ¨¡å—
æä¾›ä»£ç é‡æ„ã€æ€§èƒ½ä¼˜åŒ–å’Œæ¶æ„æ”¹è¿›åŠŸèƒ½
"""

import ast
import os
import sys
import time
import json
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import importlib.util

class OptimizationType(Enum):
    """ä¼˜åŒ–ç±»å‹"""
    CODE_REFACTOR = "code_refactor"
    PERFORMANCE = "performance"
    ARCHITECTURE = "architecture"
    MEMORY = "memory"
    ALGORITHM = "algorithm"

class CodeQuality(Enum):
    """ä»£ç è´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    CRITICAL = "critical"

@dataclass
class CodeMetrics:
    """ä»£ç åº¦é‡æŒ‡æ ‡"""
    lines_of_code: int = 0
    cyclomatic_complexity: int = 0
    function_count: int = 0
    class_count: int = 0
    import_count: int = 0
    comment_ratio: float = 0.0
    duplication_ratio: float = 0.0
    test_coverage: float = 0.0

@dataclass
class OptimizationSuggestion:
    """ä¼˜åŒ–å»ºè®®"""
    type: OptimizationType
    priority: str  # high, medium, low
    description: str
    file_path: str
    line_number: Optional[int] = None
    estimated_impact: str = "medium"  # high, medium, low
    implementation_effort: str = "medium"  # high, medium, low

@dataclass
class RefactorReport:
    """é‡æ„æŠ¥å‘Š"""
    file_path: str
    original_metrics: CodeMetrics
    optimized_metrics: CodeMetrics
    suggestions: List[OptimizationSuggestion] = field(default_factory=list)
    quality_score: float = 0.0
    quality_grade: CodeQuality = CodeQuality.FAIR

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def analyze_file(self, file_path: str) -> CodeMetrics:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„ä»£ç åº¦é‡"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            metrics = CodeMetrics()
            metrics.lines_of_code = len(content.splitlines())
            metrics.function_count = len([node for node in ast.walk(tree) 
                                        if isinstance(node, ast.FunctionDef)])
            metrics.class_count = len([node for node in ast.walk(tree) 
                                     if isinstance(node, ast.ClassDef)])
            metrics.import_count = len([node for node in ast.walk(tree) 
                                      if isinstance(node, (ast.Import, ast.ImportFrom))])
            
            # è®¡ç®—æ³¨é‡Šæ¯”ä¾‹
            comment_lines = len([line for line in content.splitlines() 
                               if line.strip().startswith('#')])
            metrics.comment_ratio = comment_lines / max(metrics.lines_of_code, 1)
            
            # è®¡ç®—åœˆå¤æ‚åº¦
            metrics.cyclomatic_complexity = self._calculate_complexity(tree)
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return CodeMetrics()
    
    def _calculate_complexity(self, tree: ast.AST) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(node, ast.ExceptHandler):
                complexity += 1
            elif isinstance(node, ast.With):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity
    
    def detect_code_smells(self, file_path: str) -> List[OptimizationSuggestion]:
        """æ£€æµ‹ä»£ç å¼‚å‘³"""
        suggestions = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # æ£€æµ‹é•¿å‡½æ•°
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_lines = node.end_lineno - node.lineno + 1
                    if func_lines > 50:
                        suggestions.append(OptimizationSuggestion(
                            type=OptimizationType.CODE_REFACTOR,
                            priority="medium",
                            description=f"å‡½æ•° {node.name} è¿‡é•¿ ({func_lines} è¡Œ)ï¼Œå»ºè®®æ‹†åˆ†",
                            file_path=file_path,
                            line_number=node.lineno
                        ))
            
            # æ£€æµ‹æ·±å±‚åµŒå¥—
            self._check_nesting_depth(tree, file_path, suggestions)
            
            # æ£€æµ‹é‡å¤ä»£ç 
            self._check_code_duplication(content, file_path, suggestions)
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹ä»£ç å¼‚å‘³æ—¶å‡ºé”™: {e}")
        
        return suggestions
    
    def _check_nesting_depth(self, tree: ast.AST, file_path: str, 
                           suggestions: List[OptimizationSuggestion]):
        """æ£€æŸ¥åµŒå¥—æ·±åº¦"""
        def get_depth(node, current_depth=0):
            max_depth = current_depth
            for child in ast.iter_child_nodes(node):
                if isinstance(child, (ast.If, ast.While, ast.For, ast.With)):
                    child_depth = get_depth(child, current_depth + 1)
                    max_depth = max(max_depth, child_depth)
            return max_depth
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                depth = get_depth(node)
                if depth > 4:
                    suggestions.append(OptimizationSuggestion(
                        type=OptimizationType.CODE_REFACTOR,
                        priority="high",
                        description=f"å‡½æ•° {node.name} åµŒå¥—è¿‡æ·± (æ·±åº¦: {depth})ï¼Œå»ºè®®é‡æ„",
                        file_path=file_path,
                        line_number=node.lineno
                    ))
    
    def _check_code_duplication(self, content: str, file_path: str, 
                              suggestions: List[OptimizationSuggestion]):
        """æ£€æŸ¥ä»£ç é‡å¤"""
        lines = content.splitlines()
        line_groups = {}
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            if len(stripped) > 10 and not stripped.startswith('#'):
                if stripped in line_groups:
                    line_groups[stripped].append(i + 1)
                else:
                    line_groups[stripped] = [i + 1]
        
        for line, occurrences in line_groups.items():
            if len(occurrences) > 2:
                suggestions.append(OptimizationSuggestion(
                    type=OptimizationType.CODE_REFACTOR,
                    priority="medium",
                    description=f"å‘ç°é‡å¤ä»£ç : '{line[:50]}...' (å‡ºç° {len(occurrences)} æ¬¡)",
                    file_path=file_path,
                    line_number=occurrences[0]
                ))

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def analyze_performance_bottlenecks(self, file_path: str) -> List[OptimizationSuggestion]:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        suggestions = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # æ£€æµ‹ä½æ•ˆçš„å¾ªç¯
            self._check_inefficient_loops(tree, file_path, suggestions)
            
            # æ£€æµ‹ä¸å¿…è¦çš„è®¡ç®—
            self._check_redundant_computations(tree, file_path, suggestions)
            
            # æ£€æµ‹å†…å­˜æ³„æ¼é£é™©
            self._check_memory_leaks(tree, file_path, suggestions)
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ€§èƒ½ç“¶é¢ˆæ—¶å‡ºé”™: {e}")
        
        return suggestions
    
    def _check_inefficient_loops(self, tree: ast.AST, file_path: str, 
                               suggestions: List[OptimizationSuggestion]):
        """æ£€æŸ¥ä½æ•ˆå¾ªç¯"""
        for node in ast.walk(tree):
            if isinstance(node, ast.For):
                # æ£€æŸ¥åµŒå¥—å¾ªç¯
                nested_loops = [child for child in ast.walk(node) 
                              if isinstance(child, (ast.For, ast.While)) and child != node]
                if len(nested_loops) >= 2:
                    suggestions.append(OptimizationSuggestion(
                        type=OptimizationType.PERFORMANCE,
                        priority="high",
                        description="å‘ç°å¤šé‡åµŒå¥—å¾ªç¯ï¼Œå¯èƒ½å½±å“æ€§èƒ½",
                        file_path=file_path,
                        line_number=node.lineno
                    ))
    
    def _check_redundant_computations(self, tree: ast.AST, file_path: str, 
                                    suggestions: List[OptimizationSuggestion]):
        """æ£€æŸ¥å†—ä½™è®¡ç®—"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„åˆ†æé€»è¾‘
        pass
    
    def _check_memory_leaks(self, tree: ast.AST, file_path: str, 
                          suggestions: List[OptimizationSuggestion]):
        """æ£€æŸ¥å†…å­˜æ³„æ¼é£é™©"""
        # æ£€æŸ¥æœªå…³é—­çš„æ–‡ä»¶å¥æŸ„
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Name) and 
                    node.func.id == 'open'):
                    # æ£€æŸ¥æ˜¯å¦åœ¨withè¯­å¥ä¸­
                    parent = node
                    in_with = False
                    # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„ASTéå†é€»è¾‘
                    if not in_with:
                        suggestions.append(OptimizationSuggestion(
                            type=OptimizationType.MEMORY,
                            priority="medium",
                            description="å»ºè®®ä½¿ç”¨ with è¯­å¥ç®¡ç†æ–‡ä»¶èµ„æº",
                            file_path=file_path,
                            line_number=node.lineno
                        ))

class ArchitectureOptimizer:
    """æ¶æ„ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def analyze_architecture(self, project_path: str) -> List[OptimizationSuggestion]:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        suggestions = []
        
        # åˆ†ææ¨¡å—ä¾èµ–
        dependencies = self._analyze_dependencies(project_path)
        
        # æ£€æŸ¥å¾ªç¯ä¾èµ–
        circular_deps = self._detect_circular_dependencies(dependencies)
        if circular_deps:
            suggestions.append(OptimizationSuggestion(
                type=OptimizationType.ARCHITECTURE,
                priority="high",
                description=f"å‘ç°å¾ªç¯ä¾èµ–: {circular_deps}",
                file_path=project_path
            ))
        
        # æ£€æŸ¥æ¨¡å—è€¦åˆåº¦
        coupling_issues = self._analyze_coupling(dependencies)
        suggestions.extend(coupling_issues)
        
        return suggestions
    
    def _analyze_dependencies(self, project_path: str) -> Dict[str, Set[str]]:
        """åˆ†ææ¨¡å—ä¾èµ–å…³ç³»"""
        dependencies = {}
        
        for py_file in Path(project_path).glob("*.py"):
            if py_file.name.startswith('__'):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                imports = set()
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.add(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            imports.add(node.module)
                
                dependencies[py_file.stem] = imports
                
            except Exception as e:
                self.logger.error(f"åˆ†æä¾èµ–æ—¶å‡ºé”™: {e}")
        
        return dependencies
    
    def _detect_circular_dependencies(self, dependencies: Dict[str, Set[str]]) -> List[str]:
        """æ£€æµ‹å¾ªç¯ä¾èµ–"""
        # ç®€åŒ–çš„å¾ªç¯ä¾èµ–æ£€æµ‹
        circular = []
        
        for module, deps in dependencies.items():
            for dep in deps:
                if dep in dependencies and module in dependencies[dep]:
                    circular.append(f"{module} <-> {dep}")
        
        return circular
    
    def _analyze_coupling(self, dependencies: Dict[str, Set[str]]) -> List[OptimizationSuggestion]:
        """åˆ†ææ¨¡å—è€¦åˆåº¦"""
        suggestions = []
        
        for module, deps in dependencies.items():
            if len(deps) > 10:
                suggestions.append(OptimizationSuggestion(
                    type=OptimizationType.ARCHITECTURE,
                    priority="medium",
                    description=f"æ¨¡å— {module} ä¾èµ–è¿‡å¤š ({len(deps)} ä¸ª)ï¼Œå»ºè®®è§£è€¦",
                    file_path=f"{module}.py"
                ))
        
        return suggestions

class CoreOptimizer:
    """æ ¸å¿ƒä¼˜åŒ–å™¨"""
    
    def __init__(self, project_path: str):
        self.project_path = project_path
        self.code_analyzer = CodeAnalyzer()
        self.performance_optimizer = PerformanceOptimizer()
        self.architecture_optimizer = ArchitectureOptimizer()
        self.logger = logging.getLogger(__name__)
    
    def run_full_optimization_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–åˆ†æ"""
        print("ğŸ” å¼€å§‹æ ¸å¿ƒä»£ç ä¼˜åŒ–åˆ†æ...")
        
        results = {
            'files_analyzed': 0,
            'total_suggestions': 0,
            'reports': [],
            'summary': {
                'code_quality': {},
                'performance_issues': 0,
                'architecture_issues': 0,
                'refactor_suggestions': 0
            }
        }
        
        # åˆ†ææ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in Path(self.project_path).glob("*.py"):
            if py_file.name.startswith('__'):
                continue
            
            print(f"ğŸ“Š åˆ†ææ–‡ä»¶: {py_file.name}")
            report = self._analyze_single_file(str(py_file))
            results['reports'].append(report)
            results['files_analyzed'] += 1
            results['total_suggestions'] += len(report.suggestions)
        
        # æ¶æ„åˆ†æ
        print("ğŸ—ï¸ åˆ†æé¡¹ç›®æ¶æ„...")
        arch_suggestions = self.architecture_optimizer.analyze_architecture(self.project_path)
        results['summary']['architecture_issues'] = len(arch_suggestions)
        
        # æ±‡æ€»ç»Ÿè®¡
        self._generate_summary(results)
        
        print(f"âœ… åˆ†æå®Œæˆï¼å…±åˆ†æ {results['files_analyzed']} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“‹ å‘ç° {results['total_suggestions']} ä¸ªä¼˜åŒ–å»ºè®®")
        
        return results
    
    def _analyze_single_file(self, file_path: str) -> RefactorReport:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        report = RefactorReport(
            file_path=file_path,
            original_metrics=self.code_analyzer.analyze_file(file_path),
            optimized_metrics=CodeMetrics()  # ä¼˜åŒ–åçš„åº¦é‡
        )
        
        # ä»£ç å¼‚å‘³æ£€æµ‹
        code_smells = self.code_analyzer.detect_code_smells(file_path)
        report.suggestions.extend(code_smells)
        
        # æ€§èƒ½åˆ†æ
        perf_issues = self.performance_optimizer.analyze_performance_bottlenecks(file_path)
        report.suggestions.extend(perf_issues)
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        report.quality_score = self._calculate_quality_score(report.original_metrics, report.suggestions)
        report.quality_grade = self._get_quality_grade(report.quality_score)
        
        return report
    
    def _calculate_quality_score(self, metrics: CodeMetrics, 
                               suggestions: List[OptimizationSuggestion]) -> float:
        """è®¡ç®—ä»£ç è´¨é‡åˆ†æ•°"""
        base_score = 100.0
        
        # æ ¹æ®åº¦é‡æŒ‡æ ‡æ‰£åˆ†
        if metrics.cyclomatic_complexity > 10:
            base_score -= (metrics.cyclomatic_complexity - 10) * 2
        
        if metrics.comment_ratio < 0.1:
            base_score -= 10
        
        # æ ¹æ®å»ºè®®æ‰£åˆ†
        for suggestion in suggestions:
            if suggestion.priority == "high":
                base_score -= 15
            elif suggestion.priority == "medium":
                base_score -= 10
            else:
                base_score -= 5
        
        return max(0, min(100, base_score))
    
    def _get_quality_grade(self, score: float) -> CodeQuality:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 90:
            return CodeQuality.EXCELLENT
        elif score >= 80:
            return CodeQuality.GOOD
        elif score >= 70:
            return CodeQuality.FAIR
        elif score >= 60:
            return CodeQuality.POOR
        else:
            return CodeQuality.CRITICAL
    
    def _generate_summary(self, results: Dict[str, Any]):
        """ç”Ÿæˆæ±‡æ€»ä¿¡æ¯"""
        quality_counts = {}
        perf_count = 0
        refactor_count = 0
        
        for report in results['reports']:
            grade = report.quality_grade.value
            quality_counts[grade] = quality_counts.get(grade, 0) + 1
            
            for suggestion in report.suggestions:
                if suggestion.type == OptimizationType.PERFORMANCE:
                    perf_count += 1
                elif suggestion.type == OptimizationType.CODE_REFACTOR:
                    refactor_count += 1
        
        results['summary']['code_quality'] = quality_counts
        results['summary']['performance_issues'] = perf_count
        results['summary']['refactor_suggestions'] = refactor_count
    
    def generate_optimization_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ”§ æ ¸å¿ƒä»£ç ä¼˜åŒ–åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report.append(f"   åˆ†ææ–‡ä»¶æ•°: {results['files_analyzed']}")
        report.append(f"   ä¼˜åŒ–å»ºè®®æ•°: {results['total_suggestions']}")
        report.append("")
        
        # ä»£ç è´¨é‡åˆ†å¸ƒ
        report.append("ğŸ¯ ä»£ç è´¨é‡åˆ†å¸ƒ:")
        for grade, count in results['summary']['code_quality'].items():
            report.append(f"   {grade}: {count} ä¸ªæ–‡ä»¶")
        report.append("")
        
        # é—®é¢˜åˆ†ç±»
        report.append("ğŸ” é—®é¢˜åˆ†ç±»:")
        report.append(f"   æ€§èƒ½é—®é¢˜: {results['summary']['performance_issues']}")
        report.append(f"   é‡æ„å»ºè®®: {results['summary']['refactor_suggestions']}")
        report.append(f"   æ¶æ„é—®é¢˜: {results['summary']['architecture_issues']}")
        report.append("")
        
        # è¯¦ç»†å»ºè®®
        report.append("ğŸ“‹ è¯¦ç»†å»ºè®®:")
        for file_report in results['reports']:
            if file_report.suggestions:
                report.append(f"\nğŸ“ {Path(file_report.file_path).name}:")
                report.append(f"   è´¨é‡è¯„çº§: {file_report.quality_grade.value}")
                report.append(f"   è´¨é‡åˆ†æ•°: {file_report.quality_score:.1f}")
                
                for suggestion in file_report.suggestions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                    report.append(f"   â€¢ {suggestion.description}")
        
        return "\n".join(report)
    
    def export_results(self, results: Dict[str, Any], output_file: str):
        """å¯¼å‡ºç»“æœåˆ°æ–‡ä»¶"""
        try:
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            serializable_results = self._make_serializable(results)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ ç»“æœå·²å¯¼å‡ºåˆ°: {output_file}")
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºç»“æœæ—¶å‡ºé”™: {e}")
    
    def _make_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            return self._make_serializable(obj.__dict__)
        elif isinstance(obj, Enum):
            return obj.value
        else:
            return obj

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ ¸å¿ƒä»£ç ä¼˜åŒ–åˆ†æå·¥å…·")
    parser.add_argument("--project", default=".", help="é¡¹ç›®è·¯å¾„")
    parser.add_argument("--output", default="optimization_report.json", help="è¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    
    optimizer = CoreOptimizer(args.project)
    results = optimizer.run_full_optimization_analysis()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = optimizer.generate_optimization_report(results)
    print(report)
    
    # å¯¼å‡ºç»“æœ
    optimizer.export_results(results, args.output)

if __name__ == "__main__":
    main()